{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPjxVTQHpDQpIikdQ8AKHR6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ludoveltz/test_github_fev25/blob/main/Excs_1_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pymupdf\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "791ZSsNK5996",
        "outputId": "b298695f-1717-4011-972c-523b164cc4c7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymupdf\n",
            "  Downloading pymupdf-1.25.4-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading pymupdf-1.25.4-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymupdf\n",
            "Successfully installed pymupdf-1.25.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install requests PyPDF2 transformers torch\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "GZf1SrLM4fIV",
        "outputId": "491d5ba9-8020-405e-d5e1-d3e7d73c9d23"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.11/dist-packages (3.0.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.29.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m94.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🌟 Exercise 1: Cartographie de la Structure de l'Article\n",
        "\n",
        "## 1. Localisation des Sections\n",
        "\n",
        "### Introduction (Section 1)\n",
        "**Résumé**: Cette section présente le contexte des services d'IA générative basés sur les LLM dans un environnement d'entreprise. Elle établit l'importance d'une architecture adaptée pour l'implémentation des LLM avec les données d'entreprise.\n",
        "\n",
        "### Related Work (Section 2)\n",
        "**Résumé**: Examine les travaux antérieurs sur les architectures LLM et leur application dans les entreprises. Cette section analyse également les différentes approches d'intégration des LLM avec les données d'entreprise existantes.\n",
        "\n",
        "### Methods (Section 3)\n",
        "**Résumé**: Détaille l'architecture proposée pour l'implémentation des services d'IA générative, incluant le traitement des données d'entreprise, les composants de sécurité, et les mécanismes d'intégration des LLM.\n",
        "\n",
        "### Experiment (Section 4)\n",
        "**Résumé**: Présente les résultats de l'implémentation de l'architecture proposée, avec des métriques de performance, des cas d'utilisation concrets, et une évaluation de l'efficacité du système.\n",
        "\n",
        "### Conclusion (Section 5)\n",
        "**Résumé**: Synthétise les découvertes principales et propose des recommandations pour l'implémentation future des services d'IA générative dans les entreprises.\n",
        "\n",
        "## 2. Format de l'Article\n",
        "\n",
        "L'article suit le format IMRaD (Introduction, Methods, Results, and Discussion) avec quelques adaptations :\n",
        "\n",
        "### Structure Standard IMRaD :\n",
        "- ✅ Introduction\n",
        "- ✅ Méthodologie\n",
        "- ✅ Résultats\n",
        "- ✅ Discussion/Conclusion\n",
        "\n",
        "### Éléments Supplémentaires :\n",
        "- Section \"Related Work\" détaillée\n",
        "- Architecture proposée\n",
        "- Cas d'utilisation pratiques\n",
        "\n",
        "### Éléments Manquants ou Moins Développés :\n",
        "- Limitations détaillées\n",
        "- Perspectives futures approfondies\n",
        "- Discussion des implications éthiques\n",
        "- Analyse comparative approfondie avec d'autres architectures\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9skk4kqa1jHM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🌟 Exercice 2 : Analyse Critique du Design Expérimental\n",
        "\n",
        "## Analyse des Sections \"Expérience\" et \"Méthodes\"\n",
        "\n",
        "### 1. Question de Recherche\n",
        "\"Comment les développeurs interagissent-ils avec les LLM dans leurs workflows de développement et quels sont les défis spécifiques qu'ils rencontrent lors de l'intégration et l'utilisation des LLM ?\"\n",
        "\n",
        "### 2. Type d'Étude\n",
        "- Étude empirique mixte (qualitative et quantitative)\n",
        "- Analyse systématique des pratiques de développement\n",
        "- Collecte de données multi-sources incluant :\n",
        "  * Enquêtes développeurs\n",
        "  * Analyse de code\n",
        "  * Documentation technique\n",
        "  * Issues GitHub\n",
        "\n",
        "### 3. Variables\n",
        "**Variables Indépendantes :**\n",
        "- Expérience des développeurs avec les LLM\n",
        "- Types d'applications développées\n",
        "- Contextes d'utilisation des LLM\n",
        "- Frameworks et outils utilisés\n",
        "\n",
        "**Variables Dépendantes :**\n",
        "- Fréquence et types d'erreurs rencontrées\n",
        "- Temps de développement\n",
        "- Qualité du code produit\n",
        "- Satisfaction des développeurs\n",
        "\n",
        "### 4. Datasets et Outils Utilisés\n",
        "**Datasets :**\n",
        "- Repositories GitHub publics\n",
        "- Forums de développeurs\n",
        "- Documentation API\n",
        "- Logs d'erreurs\n",
        "- Retours d'expérience\n",
        "\n",
        "**Outils :**\n",
        "- Outils d'analyse de code\n",
        "- Frameworks LLM\n",
        "- Outils de tracking de bugs\n",
        "- Systèmes de versioning\n",
        "\n",
        "### 5. Contrôles et Comparaisons\n",
        "- Comparaison avec méthodes de développement traditionnelles\n",
        "- Benchmarking avec différents LLM\n",
        "- Analyse comparative des pratiques\n",
        "- Validation par experts du domaine\n",
        "\n",
        "### 6. Reproductibilité et Transparence\n",
        "**Forces :**\n",
        "- Méthodologie clairement documentée\n",
        "- Code source disponible\n",
        "- Données d'analyse accessibles\n",
        "- Critères d'évaluation définis\n",
        "\n",
        "**Limitations :**\n",
        "- Évolution rapide des LLM\n",
        "- Variabilité des contextes d'utilisation\n",
        "- Biais potentiels dans la sélection des données\n",
        "- Complexité des workflows de développement\n"
      ],
      "metadata": {
        "id": "6t6o53fe2Ad2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🌟 Exercise 3: Évaluation des Métriques et Preuves\n",
        "\n",
        "## 1. Comparaisons de Performance\n",
        "- L'article présente principalement des comparaisons entre différentes approches d'implémentation de services d'IA générative\n",
        "- Les comparaisons se concentrent sur l'architecture RAG (Retrieval-Augmented Generation) pour l'intégration des données d'entreprise\n",
        "- Il n'y a pas de comparaison directe et quantitative entre différents modèles LLM (comme GPT-3.5 vs GPT-4)\n",
        "\n",
        "## 2. Métriques d'Évaluation Utilisées\n",
        "L'article utilise principalement des métriques qualitatives :\n",
        "- Faisabilité de l'implémentation\n",
        "- Capacité d'intégration avec les systèmes existants\n",
        "- Adaptabilité aux différents cas d'usage\n",
        "- Efficacité de la récupération d'informations\n",
        "\n",
        "## 3. Pertinence des Métriques\n",
        "Points Positifs :\n",
        "- Les métriques qualitatives sont appropriées pour une étude d'implémentation\n",
        "- L'accent mis sur l'intégration pratique correspond aux objectifs de l'étude\n",
        "\n",
        "Points Faibles :\n",
        "- Manque de métriques quantitatives\n",
        "- Absence de benchmarks standardisés\n",
        "- Pas d'évaluation comparative systématique\n",
        "\n",
        "## 4. Suggestions d'Amélioration\n",
        "Pour renforcer la validité des résultats, l'article pourrait inclure :\n",
        "\n",
        "Métriques Quantitatives :\n",
        "- Temps de latence des requêtes\n",
        "- Taux de précision des réponses\n",
        "- Consommation de ressources\n",
        "- Coûts d'implémentation\n",
        "\n",
        "Évaluations Qualitatives Supplémentaires :\n",
        "- Retours utilisateurs structurés\n",
        "- Évaluation par des experts du domaine\n",
        "- Tests A/B comparatifs\n",
        "- Études de cas détaillées\n",
        "\n",
        "Métriques Techniques :\n",
        "- Performances du système RAG\n",
        "- Vitesse de récupération des données\n",
        "- Qualité de la génération\n",
        "- Taux d'erreur\n",
        "\n",
        "Validation Externe :\n",
        "- Comparaisons avec d'autres architectures\n",
        "- Benchmarks industriels\n",
        "- Évaluation par des tiers\n",
        "- Études longitudinales\n"
      ],
      "metadata": {
        "id": "bWzumsyBdmuA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tabulate\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbOm8lMie_IT",
        "outputId": "7ae49feb-a1f4-466d-d0f6-b3201ced56a1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (0.9.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Importation des bibliothèques\n",
        "from tabulate import tabulate\n",
        "from IPython.display import Markdown, display\n",
        "import pandas as pd\n",
        "\n",
        "# Création des notes Cornell\n",
        "def create_cornell_notes():\n",
        "    # Création du DataFrame pour la structure principale\n",
        "    cornell_data = {\n",
        "        'Questions/Termes Clés': [\n",
        "            'Qu\\'est-ce que le RAG ?',\n",
        "            'Comment fonctionne le processus de chunking ?',\n",
        "            'Quels sont les composants principaux ?',\n",
        "            'Comment s\\'effectue l\\'implémentation ?'\n",
        "        ],\n",
        "        'Notes': [\n",
        "            '• Retrieval Augmented Generation\\n• Méthode combinant LLM avec données externes\\n• Permet d\\'améliorer précision des réponses',\n",
        "            '• Découpage documents en chunks\\n• Conversion en embeddings vectoriels\\n• Stockage dans base vectorielle',\n",
        "            '• Vector Store (ChromaDB)\\n• Embedding Model\\n• LLM pour génération',\n",
        "            '1. Préparation documents\\n2. Création embeddings\\n3. Stockage vectoriel\\n4. Requête et récupération\\n5. Génération réponse'\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    # Création du DataFrame\n",
        "    df = pd.DataFrame(cornell_data)\n",
        "\n",
        "    # Affichage du titre\n",
        "    display(Markdown('# Notes Cornell - RAG Based Implementation Procedure'))\n",
        "\n",
        "    # Affichage de la structure principale\n",
        "    display(Markdown(tabulate(df, headers='keys', tablefmt='pipe', showindex=False)))\n",
        "\n",
        "    # Affichage du résumé\n",
        "    display(Markdown(\"\"\"\n",
        "## Résumé\n",
        "\n",
        "La section 3.2.1 détaille l'implémentation d'un système RAG pour améliorer les réponses des LLM avec des données d'entreprise.\n",
        "Le processus comprend le découpage des documents, leur transformation en vecteurs, et leur stockage pour une récupération contextuelle.\n",
        "Cette approche permet d'obtenir des réponses plus précises et pertinentes en combinant la puissance des LLM avec des données spécifiques à l'entreprise.\n",
        "\"\"\"))\n",
        "\n",
        "# Exécution de la fonction\n",
        "create_cornell_notes()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 671
        },
        "id": "HEEYbHlvfFSk",
        "outputId": "e362ce25-8e8e-4896-efe2-d0a61e83fe6f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (0.9.0)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Notes Cornell - RAG Based Implementation Procedure"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "| Questions/Termes Clés                         | Notes                                         |\n|:----------------------------------------------|:----------------------------------------------|\n| Qu'est-ce que le RAG ?                        | • Retrieval Augmented Generation              |\n|                                               | • Méthode combinant LLM avec données externes |\n|                                               | • Permet d'améliorer précision des réponses   |\n| Comment fonctionne le processus de chunking ? | • Découpage documents en chunks               |\n|                                               | • Conversion en embeddings vectoriels         |\n|                                               | • Stockage dans base vectorielle              |\n| Quels sont les composants principaux ?        | • Vector Store (ChromaDB)                     |\n|                                               | • Embedding Model                             |\n|                                               | • LLM pour génération                         |\n| Comment s'effectue l'implémentation ?         | 1. Préparation documents                      |\n|                                               | 2. Création embeddings                        |\n|                                               | 3. Stockage vectoriel                         |\n|                                               | 4. Requête et récupération                    |\n|                                               | 5. Génération réponse                         |"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n## Résumé\n\nLa section 3.2.1 détaille l'implémentation d'un système RAG pour améliorer les réponses des LLM avec des données d'entreprise. \nLe processus comprend le découpage des documents, leur transformation en vecteurs, et leur stockage pour une récupération contextuelle. \nCette approche permet d'obtenir des réponses plus précises et pertinentes en combinant la puissance des LLM avec des données spécifiques à l'entreprise.\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5W1H Analysis\n",
        "\n",
        "**Who (Qui) ?**\n",
        "Les auteurs de l'étude sont des chercheurs travaillant sur l'implémentation des services d'IA générative dans un contexte d'entreprise.\n",
        "\n",
        "**What (Quoi) ?**\n",
        "Une architecture d'application LLM basée sur les données d'entreprise pour l'implémentation de services d'IA générative, avec un focus particulier sur l'approche RAG (Retrieval-Augmented Generation).\n",
        "\n",
        "**When & Where (Quand & Où) ?**\n",
        "L'article a été publié sur arXiv en septembre 2023 (2309.01105).\n",
        "\n",
        "**Why (Pourquoi) ?**\n",
        "Le problème est important car les entreprises ont besoin d'intégrer efficacement les LLM avec leurs données propriétaires tout en maintenant la sécurité et la pertinence des réponses générées.\n",
        "\n",
        "**How (Comment) ?**\n",
        "La solution a été implémentée via une architecture RAG qui combine :\n",
        "- Préparation et chunking des documents\n",
        "- Création d'embeddings vectoriels\n",
        "- Stockage dans une base de données vectorielle\n",
        "- Système de récupération contextuelle\n",
        "- Génération de réponses avec LLM\n",
        "\n",
        "### Résumé en 4 phrases\n",
        "\n",
        "**Objectif :**\n",
        "L'étude visait à développer une architecture pratique pour l'implémentation de services d'IA générative dans un contexte d'entreprise, en se concentrant sur l'intégration efficace des données propriétaires avec les capacités des LLM.\n",
        "\n",
        "**Méthodologie :**\n",
        "Les chercheurs ont adopté une approche basée sur RAG, combinant des techniques de traitement de documents, d'indexation vectorielle et de génération de texte, tout en mettant l'accent sur la sécurité et la pertinence des données.\n",
        "\n",
        "**Découvertes/Constructions :**\n",
        "Ils ont développé une architecture complète qui permet aux entreprises d'implémenter des services d'IA générative en utilisant leurs propres données, avec des mécanismes de contrôle et de récupération contextuelle.\n",
        "\n",
        "**Implications pratiques :**\n",
        "Cette architecture fournit un cadre concret pour les entreprises souhaitant déployer des services d'IA générative, offrant un équilibre entre performance, sécurité et pertinence des réponses, tout en permettant une intégration harmonieuse avec les systèmes existants.\n"
      ],
      "metadata": {
        "id": "wX9goNnCe7eM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🌟 Exercise 6 : Réflexion sur l'Architecture RAG + LLM\n",
        "\n",
        "### 1. Cas d'Utilisation\n",
        "**Assistant Créatif pour Marques de Luxe**\n",
        "Un système qui aide à générer et valider des concepts créatifs en respectant l'ADN des marques de luxe.\n",
        "\n",
        "### 2. Pipeline RAG Simplifié\n",
        "\n",
        "**Données à Collecter et Chunking :**\n",
        "- Archives des campagnes précédentes\n",
        "- Guides de style des marques\n",
        "- Documentation technique des proportions historiques\n",
        "- Systèmes de tagging propriétaires\n",
        "- Palettes de couleurs et signatures visuelles\n",
        "\n",
        "**Chunking Strategy :**\n",
        "- Découpage par éléments visuels cohérents\n",
        "- Séparation des aspects techniques et créatifs\n",
        "- Préservation des associations couleur-concept\n",
        "- Maintien des proportions dans les chunks\n",
        "\n",
        "**Base de Données Vectorielle : Chroma DB**\n",
        "Raisons du choix :\n",
        "- Excellente gestion des embeddings multimodaux\n",
        "- Intégration facile avec les frameworks de ML\n",
        "- Performance optimale pour les requêtes visuelles\n",
        "- Support des métadonnées riches\n",
        "\n",
        "**LLM Choisi : GPT-4 avec Fine-tuning**\n",
        "Justification :\n",
        "- Capacités multimodales avancées\n",
        "- Compréhension sophistiquée du contexte\n",
        "- Possibilité de fine-tuning sur données luxe\n",
        "- Support des prompts complexes\n",
        "\n",
        "**Gestion des Hallucinations :**\n",
        "- Système de validation par rapport aux guides de style\n",
        "- Vérification des proportions historiques\n",
        "- Contrôle de cohérence avec l'ADN de marque\n",
        "- Feedback loop avec experts créatifs\n",
        "\n",
        "### 3. Défis Anticipés\n",
        "\n",
        "**Défis Techniques :**\n",
        "- Intégration complexe des données visuelles et textuelles\n",
        "- Maintien de la cohérence dans les générations\n",
        "- Performance du système en temps réel\n",
        "- Gestion des versions des assets\n",
        "\n",
        "**Défis Créatifs :**\n",
        "- Préservation de l'unicité de chaque marque\n",
        "- Balance entre innovation et tradition\n",
        "- Validation des propositions créatives\n",
        "- Maintien de l'excellence artisanale\n",
        "\n",
        "**Défis d'Implémentation :**\n",
        "- Formation des équipes créatives\n",
        "- Intégration aux workflows existants\n",
        "- Sécurité des données sensibles\n",
        "- Évolutivité du système\n",
        "\n",
        "**Défis Spécifiques au Luxe :**\n",
        "- Respect des standards haute couture\n",
        "- Maintien de l'exclusivité\n",
        "- Protection de la propriété intellectuelle\n",
        "- Adaptation aux tendances tout en préservant l'héritage\n"
      ],
      "metadata": {
        "id": "zgUlxxfTga_F"
      }
    }
  ]
}