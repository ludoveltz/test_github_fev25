{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp313-cp313-macosx_12_0_arm64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from scikit-learn) (2.2.3)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.15.2-cp313-cp313-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.6.1-cp313-cp313-macosx_12_0_arm64.whl (11.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading scipy-1.15.2-cp313-cp313-macosx_14_0_arm64.whl (22.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.4/22.4 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.6.1 scipy-1.15.2 threadpoolctl-3.5.0\n"
     ]
    }
   ],
   "source": [
    "# Installation de sklearn\n",
    "!pip3 install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement du dataset météo...\n",
      "\n",
      "=== EXPLORATION DES DONNÉES ===\n",
      "\n",
      "Aperçu des premières lignes :\n",
      "                  Formatted Date        Summary Precip Type  Temperature (C)  \\\n",
      "0  2006-04-01 00:00:00.000 +0200  Partly Cloudy        rain         9.472222   \n",
      "1  2006-04-01 01:00:00.000 +0200  Partly Cloudy        rain         9.355556   \n",
      "2  2006-04-01 02:00:00.000 +0200  Mostly Cloudy        rain         9.377778   \n",
      "3  2006-04-01 03:00:00.000 +0200  Partly Cloudy        rain         8.288889   \n",
      "4  2006-04-01 04:00:00.000 +0200  Mostly Cloudy        rain         8.755556   \n",
      "\n",
      "   Apparent Temperature (C)  Humidity  Wind Speed (km/h)  \\\n",
      "0                  7.388889      0.89            14.1197   \n",
      "1                  7.227778      0.86            14.2646   \n",
      "2                  9.377778      0.89             3.9284   \n",
      "3                  5.944444      0.83            14.1036   \n",
      "4                  6.977778      0.83            11.0446   \n",
      "\n",
      "   Wind Bearing (degrees)  Visibility (km)  Loud Cover  Pressure (millibars)  \\\n",
      "0                   251.0          15.8263         0.0               1015.13   \n",
      "1                   259.0          15.8263         0.0               1015.63   \n",
      "2                   204.0          14.9569         0.0               1015.94   \n",
      "3                   269.0          15.8263         0.0               1016.41   \n",
      "4                   259.0          15.8263         0.0               1016.51   \n",
      "\n",
      "                       Daily Summary  \n",
      "0  Partly cloudy throughout the day.  \n",
      "1  Partly cloudy throughout the day.  \n",
      "2  Partly cloudy throughout the day.  \n",
      "3  Partly cloudy throughout the day.  \n",
      "4  Partly cloudy throughout the day.  \n",
      "\n",
      "Informations sur le dataset :\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 96453 entries, 0 to 96452\n",
      "Data columns (total 12 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Formatted Date            96453 non-null  object \n",
      " 1   Summary                   96453 non-null  object \n",
      " 2   Precip Type               95936 non-null  object \n",
      " 3   Temperature (C)           96453 non-null  float64\n",
      " 4   Apparent Temperature (C)  96453 non-null  float64\n",
      " 5   Humidity                  96453 non-null  float64\n",
      " 6   Wind Speed (km/h)         96453 non-null  float64\n",
      " 7   Wind Bearing (degrees)    96453 non-null  float64\n",
      " 8   Visibility (km)           96453 non-null  float64\n",
      " 9   Loud Cover                96453 non-null  float64\n",
      " 10  Pressure (millibars)      96453 non-null  float64\n",
      " 11  Daily Summary             96453 non-null  object \n",
      "dtypes: float64(8), object(4)\n",
      "memory usage: 8.8+ MB\n",
      "None\n",
      "\n",
      "Statistiques descriptives :\n",
      "       Temperature (C)  Apparent Temperature (C)      Humidity  \\\n",
      "count     96453.000000              96453.000000  96453.000000   \n",
      "mean         11.932678                 10.855029      0.734899   \n",
      "std           9.551546                 10.696847      0.195473   \n",
      "min         -21.822222                -27.716667      0.000000   \n",
      "25%           4.688889                  2.311111      0.600000   \n",
      "50%          12.000000                 12.000000      0.780000   \n",
      "75%          18.838889                 18.838889      0.890000   \n",
      "max          39.905556                 39.344444      1.000000   \n",
      "\n",
      "       Wind Speed (km/h)  Wind Bearing (degrees)  Visibility (km)  Loud Cover  \\\n",
      "count       96453.000000            96453.000000     96453.000000     96453.0   \n",
      "mean           10.810640              187.509232        10.347325         0.0   \n",
      "std             6.913571              107.383428         4.192123         0.0   \n",
      "min             0.000000                0.000000         0.000000         0.0   \n",
      "25%             5.828200              116.000000         8.339800         0.0   \n",
      "50%             9.965900              180.000000        10.046400         0.0   \n",
      "75%            14.135800              290.000000        14.812000         0.0   \n",
      "max            63.852600              359.000000        16.100000         0.0   \n",
      "\n",
      "       Pressure (millibars)  \n",
      "count          96453.000000  \n",
      "mean            1003.235956  \n",
      "std              116.969906  \n",
      "min                0.000000  \n",
      "25%             1011.900000  \n",
      "50%             1016.450000  \n",
      "75%             1021.090000  \n",
      "max             1046.380000  \n",
      "\n",
      "=== NORMALISATION DES DONNÉES ===\n",
      "La colonne de précipitations n'a pas été trouvée dans le dataset\n",
      "\n",
      "=== RÉDUCTION DES DONNÉES (PCA) ===\n",
      "\n",
      "Colonnes numériques utilisées pour PCA : ['Temperature (C)', 'Apparent Temperature (C)', 'Humidity', 'Wind Speed (km/h)', 'Wind Bearing (degrees)', 'Visibility (km)', 'Loud Cover', 'Pressure (millibars)']\n",
      "\n",
      "Aperçu des données réduites :\n",
      "         PC1        PC2\n",
      "0   7.572204  64.164119\n",
      "1   7.529264  72.179519\n",
      "2  11.592634  17.266138\n",
      "3   7.632113  82.201402\n",
      "4   8.418255  72.215926\n",
      "\n",
      "Variance expliquée par composante :\n",
      "[0.53727674 0.45212267]\n",
      "\n",
      "=== AGRÉGATION DES DONNÉES ===\n",
      "\n",
      "Vérification du format de date...\n",
      "Colonnes disponibles : ['Formatted Date', 'Summary', 'Precip Type', 'Temperature (C)', 'Apparent Temperature (C)', 'Humidity', 'Wind Speed (km/h)', 'Wind Bearing (degrees)', 'Visibility (km)', 'Loud Cover', 'Pressure (millibars)', 'Daily Summary']\n",
      "\n",
      "Type de données de 'Formatted Date': object\n",
      "Exemple de date: 2006-04-01 00:00:00.000 +0200\n",
      "Erreur lors de la conversion de la date : 'Series' object has no attribute 'date'\n",
      "Erreur lors de l'agrégation : \"Column(s) ['Precip'] do not exist\"\n",
      "\n",
      "Analyse complétée avec succès !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3h/ppgwfhhj1rz7_5v8s2zf1pwr0000gn/T/ipykernel_31457/708517675.py:102: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df['Date'] = pd.to_datetime(df['Formatted Date'])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import os\n",
    "\n",
    "def charger_dataset():\n",
    "    \"\"\"\n",
    "    Charge le dataset météo depuis le dossier spécifié\n",
    "    \"\"\"\n",
    "    try:\n",
    "        chemin = 'WEEK_2/DAY_3/DATASET/weatherHistory.csv'\n",
    "        if not os.path.exists(chemin):\n",
    "            print(f\"Erreur : Le fichier {chemin} n'existe pas\")\n",
    "            return None\n",
    "            \n",
    "        df = pd.read_csv(chemin)\n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du chargement : {e}\")\n",
    "        return None\n",
    "\n",
    "def explorer_donnees(df):\n",
    "    \"\"\"\n",
    "    Explore le dataset et affiche les informations importantes\n",
    "    \"\"\"\n",
    "    print(\"\\n=== EXPLORATION DES DONNÉES ===\")\n",
    "    print(\"\\nAperçu des premières lignes :\")\n",
    "    print(df.head())\n",
    "    \n",
    "    print(\"\\nInformations sur le dataset :\")\n",
    "    print(df.info())\n",
    "    \n",
    "    print(\"\\nStatistiques descriptives :\")\n",
    "    print(df.describe())\n",
    "\n",
    "def normaliser_precipitations(df):\n",
    "    \"\"\"\n",
    "    Effectue la normalisation Min-Max sur les précipitations\n",
    "    \"\"\"\n",
    "    print(\"\\n=== NORMALISATION DES DONNÉES ===\")\n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "    # Vérification et normalisation de la colonne de précipitations\n",
    "    if 'Precip' in df.columns:\n",
    "        df['Precipitation_normalized'] = scaler.fit_transform(df[['Precip']])\n",
    "        print(\"\\nAperçu des données normalisées :\")\n",
    "        print(df[['Precip', 'Precipitation_normalized']].head())\n",
    "    else:\n",
    "        print(\"La colonne de précipitations n'a pas été trouvée dans le dataset\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def reduction_donnees_pca(df):\n",
    "    \"\"\"\n",
    "    Applique PCA pour réduire la dimensionnalité\n",
    "    \"\"\"\n",
    "    print(\"\\n=== RÉDUCTION DES DONNÉES (PCA) ===\")\n",
    "    \n",
    "    # Sélection uniquement des colonnes numériques pour PCA\n",
    "    colonnes_numeriques = df.select_dtypes(include=[np.number]).columns\n",
    "    print(f\"\\nColonnes numériques utilisées pour PCA : {colonnes_numeriques.tolist()}\")\n",
    "    \n",
    "    # Application de PCA\n",
    "    pca = PCA(n_components=2)\n",
    "    donnees_reduites = pca.fit_transform(df[colonnes_numeriques])\n",
    "    \n",
    "    # Création d'un nouveau DataFrame avec les composantes principales\n",
    "    df_pca = pd.DataFrame(\n",
    "        donnees_reduites, \n",
    "        columns=['PC1', 'PC2']\n",
    "    )\n",
    "    \n",
    "    print(\"\\nAperçu des données réduites :\")\n",
    "    print(df_pca.head())\n",
    "    \n",
    "    # Affichage de la variance expliquée\n",
    "    print(\"\\nVariance expliquée par composante :\")\n",
    "    print(pca.explained_variance_ratio_)\n",
    "    \n",
    "    return df_pca\n",
    "\n",
    "def agreger_donnees(df):\n",
    "    \"\"\"\n",
    "    Agrège les données par date\n",
    "    \"\"\"\n",
    "    print(\"\\n=== AGRÉGATION DES DONNÉES ===\")\n",
    "    \n",
    "    try:\n",
    "        # Vérification du format de la colonne de date\n",
    "        print(\"\\nVérification du format de date...\")\n",
    "        print(\"Colonnes disponibles :\", df.columns.tolist())\n",
    "        \n",
    "        if 'Formatted Date' in df.columns:\n",
    "            # Affichage du type de données de la colonne\n",
    "            print(\"\\nType de données de 'Formatted Date':\", df['Formatted Date'].dtype)\n",
    "            print(\"Exemple de date:\", df['Formatted Date'].iloc[0])\n",
    "            \n",
    "            # Conversion en datetime avec gestion d'erreurs\n",
    "            try:\n",
    "                df['Date'] = pd.to_datetime(df['Formatted Date'])\n",
    "                \n",
    "                # Agrégation par date\n",
    "                df_agrege = df.groupby(df['Date'].date).agg({\n",
    "                    'Precip': ['mean', 'min', 'max', 'count']\n",
    "                }).round(3)\n",
    "                \n",
    "                print(\"\\nDonnées agrégées par date :\")\n",
    "                print(df_agrege.head())\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Erreur lors de la conversion de la date : {e}\")\n",
    "                # Alternative : agrégation sans conversion de date\n",
    "                df_agrege = df.groupby('Formatted Date').agg({\n",
    "                    'Precip': ['mean', 'min', 'max', 'count']\n",
    "                }).round(3)\n",
    "                print(\"\\nDonnées agrégées par date (sans conversion) :\")\n",
    "                print(df_agrege.head())\n",
    "                \n",
    "        else:\n",
    "            print(\"La colonne 'Formatted Date' n'a pas été trouvée dans le dataset\")\n",
    "            print(\"Colonnes disponibles :\", df.columns.tolist())\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de l'agrégation : {e}\")\n",
    "        return None\n",
    "    \n",
    "    return df_agrege\n",
    "\n",
    "def main():\n",
    "    # Chargement des données\n",
    "    print(\"Chargement du dataset météo...\")\n",
    "    df = charger_dataset()\n",
    "    \n",
    "    if df is not None:\n",
    "        # Exploration\n",
    "        explorer_donnees(df)\n",
    "        \n",
    "        # Normalisation\n",
    "        df = normaliser_precipitations(df)\n",
    "        \n",
    "        # Réduction\n",
    "        df_pca = reduction_donnees_pca(df)\n",
    "        \n",
    "        # Agrégation\n",
    "        df_agrege = agreger_donnees(df)\n",
    "        \n",
    "        print(\"\\nAnalyse complétée avec succès !\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
