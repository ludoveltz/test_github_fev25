{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Début de l'entraînement...\n",
      "Époque 0, Perte: 0.3662\n",
      "Époque 10, Perte: 0.3662\n",
      "Époque 20, Perte: 0.3661\n",
      "Époque 30, Perte: 0.3661\n",
      "Époque 40, Perte: 0.3661\n",
      "Époque 50, Perte: 0.3660\n",
      "Époque 60, Perte: 0.3660\n",
      "Époque 70, Perte: 0.3660\n",
      "Époque 80, Perte: 0.3659\n",
      "Époque 90, Perte: 0.3659\n",
      "\n",
      "Prédiction pour un nouvel échantillon:\n",
      "Probabilités des classes: [0.33234333 0.34093437 0.3267223 ]\n",
      "Classe prédite: 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class DeepNeuralNetwork:\n",
    "    def __init__(self, input_size=4, hidden1_size=5, hidden2_size=4, output_size=3, learning_rate=0.01):\n",
    "        \"\"\"Initialisation du réseau de neurones\"\"\"\n",
    "        self.input_size = input_size\n",
    "        self.hidden1_size = hidden1_size\n",
    "        self.hidden2_size = hidden2_size\n",
    "        self.output_size = output_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.initialize_parameters()\n",
    "\n",
    "    def initialize_parameters(self):\n",
    "        \"\"\"Initialisation des poids et biais\"\"\"\n",
    "        # Poids et biais de la première couche cachée\n",
    "        self.W1 = np.random.randn(self.input_size, self.hidden1_size) * 0.01\n",
    "        self.b1 = np.zeros((1, self.hidden1_size))\n",
    "        \n",
    "        # Poids et biais de la deuxième couche cachée\n",
    "        self.W2 = np.random.randn(self.hidden1_size, self.hidden2_size) * 0.01\n",
    "        self.b2 = np.zeros((1, self.hidden2_size))\n",
    "        \n",
    "        # Poids et biais de la couche de sortie\n",
    "        self.W3 = np.random.randn(self.hidden2_size, self.output_size) * 0.01\n",
    "        self.b3 = np.zeros((1, self.output_size))\n",
    "\n",
    "    def relu(self, Z):\n",
    "        \"\"\"Fonction d'activation ReLU\"\"\"\n",
    "        return np.maximum(0, Z)\n",
    "\n",
    "    def softmax(self, Z):\n",
    "        \"\"\"Fonction d'activation Softmax\"\"\"\n",
    "        exp_Z = np.exp(Z - np.max(Z, axis=1, keepdims=True))\n",
    "        return exp_Z / np.sum(exp_Z, axis=1, keepdims=True)\n",
    "\n",
    "    def forward_propagation(self, X):\n",
    "        \"\"\"Propagation avant\"\"\"\n",
    "        # Première couche cachée\n",
    "        self.Z1 = np.dot(X, self.W1) + self.b1\n",
    "        self.A1 = self.relu(self.Z1)\n",
    "        \n",
    "        # Deuxième couche cachée\n",
    "        self.Z2 = np.dot(self.A1, self.W2) + self.b2\n",
    "        self.A2 = self.relu(self.Z2)\n",
    "        \n",
    "        # Couche de sortie\n",
    "        self.Z3 = np.dot(self.A2, self.W3) + self.b3\n",
    "        self.A3 = self.softmax(self.Z3)\n",
    "        \n",
    "        return self.A3\n",
    "\n",
    "    def compute_loss(self, y_true, y_pred):\n",
    "        \"\"\"Calcul de la perte (cross-entropy)\"\"\"\n",
    "        return -np.mean(y_true * np.log(y_pred + 1e-8))\n",
    "\n",
    "    def backward_propagation(self, X, y):\n",
    "        \"\"\"Rétropropagation\"\"\"\n",
    "        m = X.shape[0]\n",
    "        \n",
    "        # Gradients de la couche de sortie\n",
    "        dZ3 = self.A3 - y\n",
    "        dW3 = np.dot(self.A2.T, dZ3) / m\n",
    "        db3 = np.mean(dZ3, axis=0)\n",
    "        \n",
    "        # Gradients de la deuxième couche cachée\n",
    "        dA2 = np.dot(dZ3, self.W3.T)\n",
    "        dZ2 = dA2 * (self.Z2 > 0)  # Dérivée de ReLU\n",
    "        dW2 = np.dot(self.A1.T, dZ2) / m\n",
    "        db2 = np.mean(dZ2, axis=0)\n",
    "        \n",
    "        # Gradients de la première couche cachée\n",
    "        dA1 = np.dot(dZ2, self.W2.T)\n",
    "        dZ1 = dA1 * (self.Z1 > 0)  # Dérivée de ReLU\n",
    "        dW1 = np.dot(X.T, dZ1) / m\n",
    "        db1 = np.mean(dZ1, axis=0)\n",
    "        \n",
    "        # Mise à jour des poids et biais\n",
    "        self.W1 -= self.learning_rate * dW1\n",
    "        self.b1 -= self.learning_rate * db1\n",
    "        self.W2 -= self.learning_rate * dW2\n",
    "        self.b2 -= self.learning_rate * db2\n",
    "        self.W3 -= self.learning_rate * dW3\n",
    "        self.b3 -= self.learning_rate * db3\n",
    "\n",
    "    def train(self, X, y, epochs=100):\n",
    "        \"\"\"Entraînement du réseau\"\"\"\n",
    "        losses = []\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # Propagation avant\n",
    "            y_pred = self.forward_propagation(X)\n",
    "            \n",
    "            # Calcul de la perte\n",
    "            loss = self.compute_loss(y, y_pred)\n",
    "            losses.append(loss)\n",
    "            \n",
    "            # Rétropropagation\n",
    "            self.backward_propagation(X, y)\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                print(f\"Époque {epoch}, Perte: {loss:.4f}\")\n",
    "        \n",
    "        return losses\n",
    "\n",
    "# Test du réseau\n",
    "if __name__ == \"__main__\":\n",
    "    # Création de données synthétiques pour le test\n",
    "    np.random.seed(42)\n",
    "    X = np.random.randn(100, 4)  # 100 échantillons avec 4 caractéristiques\n",
    "    y = np.eye(3)[np.random.randint(0, 3, 100)]  # 3 classes\n",
    "\n",
    "    # Création et entraînement du modèle\n",
    "    model = DeepNeuralNetwork()\n",
    "    print(\"Début de l'entraînement...\")\n",
    "    losses = model.train(X, y)\n",
    "\n",
    "    # Test avec un nouvel échantillon\n",
    "    test_sample = np.random.randn(1, 4)\n",
    "    prediction = model.forward_propagation(test_sample)\n",
    "    print(\"\\nPrédiction pour un nouvel échantillon:\")\n",
    "    print(f\"Probabilités des classes: {prediction[0]}\")\n",
    "    print(f\"Classe prédite: {np.argmax(prediction)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
