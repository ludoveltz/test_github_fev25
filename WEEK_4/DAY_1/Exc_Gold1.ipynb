{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture du réseau :\n",
      "- Couche d'entrée : 2 neurones\n",
      "- Couche cachée : 3 neurones (ReLU)\n",
      "- Couche de sortie : 1 neurone (Sigmoid)\n",
      "\n",
      "Poids de la couche cachée :\n",
      "[[ 0.00316884  0.02131119 -0.01609799]\n",
      " [ 0.00504199  0.02506933  0.00579578]]\n",
      "\n",
      "Biais de la couche cachée :\n",
      "[[0. 0. 0.]]\n",
      "\n",
      "Poids de la couche de sortie :\n",
      "[[-0.00040431]\n",
      " [-0.00227958]\n",
      " [-0.004871  ]]\n",
      "\n",
      "Biais de la couche de sortie :\n",
      "[[0.]]\n",
      "\n",
      "Résultats :\n",
      "Cas 1 (Input: [2, 3]) -> Output: 0.4999\n",
      "Cas 2 (Input: [1, 5]) -> Output: 0.4999\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MultiLayerPerceptron:\n",
    "    def __init__(self):\n",
    "        # Initialisation des poids et biais\n",
    "        # Couche cachée (2 entrées -> 3 neurones)\n",
    "        self.W1 = np.random.randn(2, 3) * 0.01\n",
    "        self.b1 = np.zeros((1, 3))\n",
    "        \n",
    "        # Couche de sortie (3 neurones -> 1 sortie)\n",
    "        self.W2 = np.random.randn(3, 1) * 0.01\n",
    "        self.b2 = np.zeros((1, 1))\n",
    "    \n",
    "    def relu(self, Z):\n",
    "        \"\"\"Fonction d'activation ReLU\"\"\"\n",
    "        return np.maximum(0, Z)\n",
    "    \n",
    "    def sigmoid(self, Z):\n",
    "        \"\"\"Fonction d'activation Sigmoid\"\"\"\n",
    "        return 1 / (1 + np.exp(-Z))\n",
    "    \n",
    "    def forward_propagation(self, X):\n",
    "        \"\"\"\n",
    "        Propagation avant\n",
    "        X: entrées (n_samples, 2)\n",
    "        \"\"\"\n",
    "        # Première couche (cachée)\n",
    "        Z1 = np.dot(X, self.W1) + self.b1\n",
    "        A1 = self.relu(Z1)\n",
    "        \n",
    "        # Deuxième couche (sortie)\n",
    "        Z2 = np.dot(A1, self.W2) + self.b2\n",
    "        A2 = self.sigmoid(Z2)\n",
    "        \n",
    "        return A2\n",
    "\n",
    "# Création du modèle\n",
    "mlp = MultiLayerPerceptron()\n",
    "\n",
    "# Test avec les cas demandés\n",
    "# Cas 1: Input (2, 3)\n",
    "X1 = np.array([[2, 3]])\n",
    "output1 = mlp.forward_propagation(X1)\n",
    "\n",
    "# Cas 2: Input (1, 5)\n",
    "X2 = np.array([[1, 5]])\n",
    "output2 = mlp.forward_propagation(X2)\n",
    "\n",
    "# Affichage des résultats\n",
    "print(\"Architecture du réseau :\")\n",
    "print(\"- Couche d'entrée : 2 neurones\")\n",
    "print(\"- Couche cachée : 3 neurones (ReLU)\")\n",
    "print(\"- Couche de sortie : 1 neurone (Sigmoid)\")\n",
    "print(\"\\nPoids de la couche cachée :\")\n",
    "print(mlp.W1)\n",
    "print(\"\\nBiais de la couche cachée :\")\n",
    "print(mlp.b1)\n",
    "print(\"\\nPoids de la couche de sortie :\")\n",
    "print(mlp.W2)\n",
    "print(\"\\nBiais de la couche de sortie :\")\n",
    "print(mlp.b2)\n",
    "print(\"\\nRésultats :\")\n",
    "print(f\"Cas 1 (Input: [2, 3]) -> Output: {output1[0][0]:.4f}\")\n",
    "print(f\"Cas 2 (Input: [1, 5]) -> Output: {output2[0][0]:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
