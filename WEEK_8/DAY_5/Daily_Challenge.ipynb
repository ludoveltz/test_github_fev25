{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyOhaQ9EUs/zkAMXHAW8ZYsY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ludoveltz/test_github_fev25/blob/main/Daily_Challenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ATAdMAlKsBQy",
        "outputId": "da4e1ca9-5348-4032-bb3b-1b8da426bcc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting farm-haystack\n",
            "  Downloading farm_haystack-1.26.4.post0-py3-none-any.whl.metadata (28 kB)\n",
            "Collecting boilerpy3 (from farm-haystack)\n",
            "  Downloading boilerpy3-1.0.7-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting events (from farm-haystack)\n",
            "  Downloading Events-0.5-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from farm-haystack) (0.28.1)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from farm-haystack) (4.23.0)\n",
            "Collecting lazy-imports==0.3.1 (from farm-haystack)\n",
            "  Downloading lazy_imports-0.3.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from farm-haystack) (10.6.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from farm-haystack) (3.4.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from farm-haystack) (2.2.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from farm-haystack) (11.1.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from farm-haystack) (4.3.7)\n",
            "Collecting posthog (from farm-haystack)\n",
            "  Downloading posthog-3.23.0-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting prompthub-py==4.0.0 (from farm-haystack)\n",
            "  Downloading prompthub_py-4.0.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting pydantic<2 (from farm-haystack)\n",
            "  Downloading pydantic-1.10.21-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (153 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.9/153.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting quantulum3 (from farm-haystack)\n",
            "  Downloading quantulum3-0.9.2-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting rank-bm25 (from farm-haystack)\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from farm-haystack) (2.32.3)\n",
            "Collecting requests-cache<1.0.0 (from farm-haystack)\n",
            "  Downloading requests_cache-0.9.8-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from farm-haystack) (1.6.1)\n",
            "Collecting sseclient-py (from farm-haystack)\n",
            "  Downloading sseclient_py-1.8.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.11/dist-packages (from farm-haystack) (9.0.0)\n",
            "Collecting tiktoken>=0.5.1 (from farm-haystack)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from farm-haystack) (4.67.1)\n",
            "Requirement already satisfied: transformers<5.0,>=4.46 in /usr/local/lib/python3.11/dist-packages (from farm-haystack) (4.50.3)\n",
            "Requirement already satisfied: pyyaml<7.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from prompthub-py==4.0.0->farm-haystack) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2->farm-haystack) (4.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->farm-haystack) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->farm-haystack) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->farm-haystack) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->farm-haystack) (2025.1.31)\n",
            "Collecting appdirs>=1.4.4 (from requests-cache<1.0.0->farm-haystack)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: attrs>=21.2 in /usr/local/lib/python3.11/dist-packages (from requests-cache<1.0.0->farm-haystack) (25.3.0)\n",
            "Collecting cattrs>=22.2 (from requests-cache<1.0.0->farm-haystack)\n",
            "  Downloading cattrs-24.1.3-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting url-normalize>=1.4 (from requests-cache<1.0.0->farm-haystack)\n",
            "  Downloading url_normalize-2.2.0-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.3.0->farm-haystack) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.3.0->farm-haystack) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.3.0->farm-haystack) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.3.0->farm-haystack) (3.6.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.5.1->farm-haystack) (2024.11.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers<5.0,>=4.46->farm-haystack) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0,>=4.46->farm-haystack) (0.30.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0,>=4.46->farm-haystack) (24.2)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0,>=4.46->farm-haystack) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0,>=4.46->farm-haystack) (0.5.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->farm-haystack) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->farm-haystack) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->farm-haystack) (0.14.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->farm-haystack) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->farm-haystack) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->farm-haystack) (0.24.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->farm-haystack) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->farm-haystack) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->farm-haystack) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from posthog->farm-haystack) (1.17.0)\n",
            "Collecting monotonic>=1.5 (from posthog->farm-haystack)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog->farm-haystack)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog->farm-haystack) (1.9.0)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.11/dist-packages (from quantulum3->farm-haystack) (7.5.0)\n",
            "Collecting num2words (from quantulum3->farm-haystack)\n",
            "  Downloading num2words-0.5.14-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers<5.0,>=4.46->farm-haystack) (2025.3.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->farm-haystack) (1.3.1)\n",
            "Requirement already satisfied: typeguard>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from inflect->quantulum3->farm-haystack) (4.4.2)\n",
            "Collecting docopt>=0.6.2 (from num2words->quantulum3->farm-haystack)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Downloading farm_haystack-1.26.4.post0-py3-none-any.whl (764 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m764.4/764.4 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lazy_imports-0.3.1-py3-none-any.whl (12 kB)\n",
            "Downloading prompthub_py-4.0.0-py3-none-any.whl (6.9 kB)\n",
            "Downloading pydantic-1.10.21-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests_cache-0.9.8-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.7/48.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boilerpy3-1.0.7-py3-none-any.whl (22 kB)\n",
            "Downloading Events-0.5-py3-none-any.whl (6.8 kB)\n",
            "Downloading posthog-3.23.0-py2.py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading quantulum3-0.9.2-py3-none-any.whl (10.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.6/10.6 MB\u001b[0m \u001b[31m121.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Downloading sseclient_py-1.8.0-py2.py3-none-any.whl (8.8 kB)\n",
            "Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading cattrs-24.1.3-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading url_normalize-2.2.0-py3-none-any.whl (14 kB)\n",
            "Downloading num2words-0.5.14-py3-none-any.whl (163 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.5/163.5 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: docopt\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=85014d6eefa4369d370670e43896932122fb2001bf473bb076fddebcaf8c7225\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/b0/8c/4b75c4116c31f83c8f9f047231251e13cc74481cca4a78a9ce\n",
            "Successfully built docopt\n",
            "Installing collected packages: sseclient-py, monotonic, events, docopt, appdirs, url-normalize, rank-bm25, pydantic, num2words, lazy-imports, cattrs, boilerpy3, backoff, tiktoken, requests-cache, prompthub-py, posthog, quantulum3, farm-haystack\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.11.1\n",
            "    Uninstalling pydantic-2.11.1:\n",
            "      Successfully uninstalled pydantic-2.11.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 2.0.5 requires pydantic>=2.9.2, but you have pydantic 1.10.21 which is incompatible.\n",
            "langchain-core 0.3.49 requires pydantic<3.0.0,>=2.5.2; python_full_version < \"3.12.4\", but you have pydantic 1.10.21 which is incompatible.\n",
            "google-genai 1.9.0 requires pydantic<3.0.0,>=2.0.0, but you have pydantic 1.10.21 which is incompatible.\n",
            "langchain 0.3.22 requires pydantic<3.0.0,>=2.7.4, but you have pydantic 1.10.21 which is incompatible.\n",
            "wandb 0.19.8 requires pydantic<3,>=2.6, but you have pydantic 1.10.21 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed appdirs-1.4.4 backoff-2.2.1 boilerpy3-1.0.7 cattrs-24.1.3 docopt-0.6.2 events-0.5 farm-haystack-1.26.4.post0 lazy-imports-0.3.1 monotonic-1.6 num2words-0.5.14 posthog-3.23.0 prompthub-py-4.0.0 pydantic-1.10.21 quantulum3-0.9.2 rank-bm25-0.2.2 requests-cache-0.9.8 sseclient-py-1.8.0 tiktoken-0.9.0 url-normalize-2.2.0\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "# 1. Installation des dépendances nécessaires\n",
        "!pip install farm-haystack\n",
        "!pip install torch torchvision torchaudio\n",
        "\n",
        "# 2. Importation des bibliothèques requises\n",
        "import logging\n",
        "from haystack.nodes import FARMReader\n",
        "from haystack.utils import clean_wiki_text\n",
        "\n",
        "# 3. Configuration du logging\n",
        "logging.basicConfig(format=\"%(levelname)s - %(name)s -  %(message)s\", level=logging.INFO)\n",
        "logging.getLogger(\"haystack\").setLevel(logging.INFO)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Création d'un dataset d'entraînement propre\n",
        "context = \"\"\"Solweig & Izar est un laboratoire créatif spécialisé dans l'IA pour le luxe, la beauté et le design. Ludovic Veltz est le Chief Technical Officer, spécialisé en IA générative, Machine Learning et développement Python avancé. La société collabore avec des clients comme Loewe, L'Oréal, Porsche, Teenage Engineering, et Spitfire Audio. Leur système de tagging propriétaire capture l'ADN créatif spécifique à chaque marque, permettant une analyse des marqueurs identitaires et la création de datasets personnalisés.\"\"\"\n",
        "\n",
        "# Fonction pour trouver l'index exact\n",
        "def find_exact_answer_start(context, answer):\n",
        "    index = context.find(answer)\n",
        "    if index == -1:\n",
        "        raise ValueError(f\"Réponse '{answer}' non trouvée dans le contexte\")\n",
        "    return index\n",
        "\n",
        "# Préparation des réponses avec vérification des indices\n",
        "answers = {\n",
        "    \"role_veltz\": \"Chief Technical Officer, spécialisé en IA générative, Machine Learning et développement Python avancé\",\n",
        "    \"clients\": \"Loewe, L'Oréal, Porsche, Teenage Engineering, et Spitfire Audio\",\n",
        "    \"tagging\": \"capture l'ADN créatif spécifique à chaque marque, permettant une analyse des marqueurs identitaires et la création de datasets personnalisés\"\n",
        "}\n",
        "\n",
        "# Création du dataset avec vérification\n",
        "training_data = {\n",
        "    \"data\": [\n",
        "        {\n",
        "            \"title\": \"Solweig & Izar\",\n",
        "            \"paragraphs\": [\n",
        "                {\n",
        "                    \"context\": context,\n",
        "                    \"qas\": [\n",
        "                        {\n",
        "                            \"question\": \"Quel est le rôle de Ludovic Veltz ?\",\n",
        "                            \"id\": \"1\",\n",
        "                            \"answers\": [\n",
        "                                {\n",
        "                                    \"text\": answers[\"role_veltz\"],\n",
        "                                    \"answer_start\": find_exact_answer_start(context, answers[\"role_veltz\"])\n",
        "                                }\n",
        "                            ]\n",
        "                        },\n",
        "                        {\n",
        "                            \"question\": \"Avec quelles marques collabore Solweig & Izar ?\",\n",
        "                            \"id\": \"2\",\n",
        "                            \"answers\": [\n",
        "                                {\n",
        "                                    \"text\": answers[\"clients\"],\n",
        "                                    \"answer_start\": find_exact_answer_start(context, answers[\"clients\"])\n",
        "                                }\n",
        "                            ]\n",
        "                        },\n",
        "                        {\n",
        "                            \"question\": \"Comment fonctionne leur système de tagging ?\",\n",
        "                            \"id\": \"3\",\n",
        "                            \"answers\": [\n",
        "                                {\n",
        "                                    \"text\": answers[\"tagging\"],\n",
        "                                    \"answer_start\": find_exact_answer_start(context, answers[\"tagging\"])\n",
        "                                }\n",
        "                            ]\n",
        "                        }\n",
        "                    ]\n",
        "                }\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Sauvegarde du dataset propre\n",
        "import json\n",
        "with open('train.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(training_data, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "# Réinitialisation et entraînement du modèle\n",
        "reader = FARMReader(model_name_or_path=\"deepset/roberta-base-squad2\", use_gpu=True)\n",
        "\n",
        "reader.train(\n",
        "    data_dir=\"./\",\n",
        "    train_filename=\"train.json\",\n",
        "    n_epochs=3,\n",
        "    learning_rate=1e-5,\n",
        "    max_seq_len=384,\n",
        "    warmup_proportion=0.2,\n",
        "    evaluate_every=100,\n",
        "    save_dir=\"my_qa_model_improved\"\n",
        ")\n",
        "\n",
        "\n",
        "# Test du modèle\n",
        "from haystack.schema import Document\n",
        "\n",
        "# Création du document de test\n",
        "doc = Document(content=training_data[\"data\"][0][\"paragraphs\"][0][\"context\"])\n",
        "\n",
        "# Questions de test\n",
        "questions = [\n",
        "    \"Quel est le rôle de Ludovic Veltz ?\",\n",
        "    \"Avec quelles marques collabore Solweig & Izar ?\",\n",
        "    \"Comment fonctionne leur système de tagging ?\"\n",
        "]\n",
        "\n",
        "# Test du modèle\n",
        "for question in questions:\n",
        "    predictions = reader.predict(\n",
        "        query=question,\n",
        "        documents=[doc],\n",
        "        top_k=1\n",
        "    )\n",
        "    print(f\"\\nQuestion: {question}\")\n",
        "    print(f\"Réponse: {predictions['answers'][0].answer}\")\n",
        "    print(f\"Score de confiance: {predictions['answers'][0].score:.2f}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLZqXWi1w24x",
        "outputId": "941667d3-5f7b-4f27-d761-72b253fd107c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:haystack.modeling.utils:Using devices: CUDA:0 - Number of GPUs: 1\n",
            "INFO:haystack.modeling.utils:Using devices: CUDA:0 - Number of GPUs: 1\n",
            "INFO:haystack.modeling.model.language_model: * LOADING MODEL: 'deepset/roberta-base-squad2' (Roberta)\n",
            "INFO:haystack.modeling.model.language_model:Auto-detected model language: english\n",
            "INFO:haystack.modeling.model.language_model:Loaded 'deepset/roberta-base-squad2' (Roberta model) from model hub.\n",
            "INFO:haystack.modeling.utils:Using devices: CUDA:0 - Number of GPUs: 1\n",
            "INFO:haystack.modeling.utils:Using devices: CUDA:0 - Number of GPUs: 1\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "Loading data into the data silo ... \n",
            "              ______\n",
            "               |o  |   !\n",
            "   __          |:`_|---'-.\n",
            "  |__|______.-/ _ \\-----.|\n",
            " (o)(o)------'\\ _ /     ( )\n",
            " \n",
            "INFO:haystack.modeling.data_handler.data_silo:LOADING TRAIN DATA\n",
            "INFO:haystack.modeling.data_handler.data_silo:==================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Loading train set from: train.json \n",
            "Preprocessing dataset: 100%|██████████| 1/1 [00:00<00:00, 254.11 Dicts/s]\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:LOADING DEV DATA\n",
            "INFO:haystack.modeling.data_handler.data_silo:=================\n",
            "INFO:haystack.modeling.data_handler.data_silo:No dev set is being loaded\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:LOADING TEST DATA\n",
            "INFO:haystack.modeling.data_handler.data_silo:=================\n",
            "INFO:haystack.modeling.data_handler.data_silo:No test set is being loaded\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.data_handler.data_silo:DATASETS SUMMARY\n",
            "INFO:haystack.modeling.data_handler.data_silo:================\n",
            "INFO:haystack.modeling.data_handler.data_silo:Examples in train: 3\n",
            "INFO:haystack.modeling.data_handler.data_silo:Examples in dev  : 0\n",
            "INFO:haystack.modeling.data_handler.data_silo:Examples in test : 0\n",
            "INFO:haystack.modeling.data_handler.data_silo:Total examples   : 3\n",
            "INFO:haystack.modeling.data_handler.data_silo:\n",
            "INFO:haystack.modeling.model.optimization:Loading optimizer 'AdamW': {'correct_bias': False, 'weight_decay': 0.01, 'lr': 1e-05}\n",
            "INFO:haystack.modeling.model.optimization:Using scheduler 'get_linear_schedule_with_warmup'\n",
            "INFO:haystack.modeling.model.optimization:Loading schedule 'get_linear_schedule_with_warmup': '{'num_training_steps': 3, 'num_warmup_steps': 0}'\n",
            "INFO:haystack.modeling.training.base:No train checkpoints found. Starting a new training ...\n",
            "Train epoch 0/2 (Cur. train loss: 0.0000): 100%|██████████| 1/1 [00:00<00:00, 19.06it/s]\n",
            "Train epoch 1/2 (Cur. train loss: 3.6693): 100%|██████████| 1/1 [00:00<00:00, 16.74it/s]\n",
            "Train epoch 2/2 (Cur. train loss: 1.8903): 100%|██████████| 1/1 [00:00<00:00, 18.90it/s]\n",
            "INFO:haystack.nodes.reader.farm:Saving reader model to my_qa_model_improved\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 89.87 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Question: Quel est le rôle de Ludovic Veltz ?\n",
            "Réponse: Chief Technical Officer\n",
            "Score de confiance: 0.84\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 96.09 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Question: Avec quelles marques collabore Solweig & Izar ?\n",
            "Réponse: Loewe, L'Oréal, Porsche, Teenage Engineering, et Spitfire Audio\n",
            "Score de confiance: 0.90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.61 Batches/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Question: Comment fonctionne leur système de tagging ?\n",
            "Réponse: capture l'ADN créatif spécifique à chaque marque\n",
            "Score de confiance: 0.37\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Import des composants nécessaires\n",
        "from haystack.nodes import BM25Retriever\n",
        "from haystack.document_stores import InMemoryDocumentStore\n",
        "from haystack.pipelines import ExtractiveQAPipeline\n",
        "from haystack.schema import Document\n",
        "\n",
        "# 2. Création de notre base de documents\n",
        "document_store = InMemoryDocumentStore(use_bm25=True)\n",
        "\n",
        "# 3. Préparation des documents avec les informations de Solweig & Izar\n",
        "documents = [\n",
        "    Document(\n",
        "        content=\"\"\"Solweig & Izar est un laboratoire créatif spécialisé dans l'IA pour le luxe, la beauté et le design.\n",
        "        La société est située au 4B Rue Pierre Guérin, 75016 Paris, France.\"\"\",\n",
        "        meta={\"type\": \"company_info\"}\n",
        "    ),\n",
        "    Document(\n",
        "        content=\"\"\"L'équipe est dirigée par Yannis Mouhoun, Creative Director expert en esthétique des marques de luxe,\n",
        "        et Ludovic Veltz, Chief Technical Officer spécialisé en IA générative et Machine Learning.\"\"\",\n",
        "        meta={\"type\": \"team\"}\n",
        "    ),\n",
        "    Document(\n",
        "        content=\"\"\"Les services incluent la création de workflows génératifs, la production de contenu itératif,\n",
        "        et le développement de concepts créatifs originaux. La société collabore avec des marques comme Gucci,\n",
        "        Cartier, Loewe, L'Oréal et Porsche.\"\"\",\n",
        "        meta={\"type\": \"services\"}\n",
        "    ),\n",
        "    Document(\n",
        "        content=\"\"\"Leur système de tagging propriétaire capture l'ADN créatif de chaque marque, permettant\n",
        "        de réduire les temps de production de 6 à 2,5 mois tout en maintenant les standards du luxe.\"\"\",\n",
        "        meta={\"type\": \"technology\"}\n",
        "    )\n",
        "]\n",
        "\n",
        "# 4. Ajout des documents au document store\n",
        "document_store.write_documents(documents)\n",
        "\n",
        "# 5. Création du retriever\n",
        "retriever = BM25Retriever(document_store=document_store)\n",
        "\n",
        "# 6. Création du pipeline complet\n",
        "pipe = ExtractiveQAPipeline(reader=reader, retriever=retriever)\n",
        "\n",
        "# 7. Test du pipeline avec des questions variées\n",
        "test_questions = [\n",
        "    \"Où sont situés les bureaux de Solweig & Izar ?\",\n",
        "    \"Quels sont les principaux clients de l'entreprise ?\",\n",
        "    \"Comment leur technologie améliore-t-elle la production ?\",\n",
        "    \"Quels services proposent-ils ?\"\n",
        "]\n",
        "\n",
        "print(\"Test du pipeline complet :\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "for question in test_questions:\n",
        "    prediction = pipe.run(\n",
        "        query=question,\n",
        "        params={\n",
        "            \"Retriever\": {\"top_k\": 2},\n",
        "            \"Reader\": {\"top_k\": 1}\n",
        "        }\n",
        "    )\n",
        "\n",
        "    answer = prediction['answers'][0]\n",
        "    print(f\"\\nQuestion: {question}\")\n",
        "    print(f\"Réponse: {answer.answer}\")\n",
        "    print(f\"Score: {answer.score:.2f}\")\n",
        "    print(f\"Document: {answer.meta['type']}\")\n",
        "    print(\"-\" * 30)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfqfevqM2B7a",
        "outputId": "d5936e82-6403-4165-8de0-d1c8bb786715"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:haystack.modeling.utils:Using devices: CUDA:0 - Number of GPUs: 1\n",
            "Updating BM25 representation...: 100%|██████████| 4/4 [00:00<00:00, 30954.27 docs/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test du pipeline complet :\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 58.36 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Question: Où sont situés les bureaux de Solweig & Izar ?\n",
            "Réponse: La société est située au 4B Rue Pierre Guérin, 75016 Paris, France\n",
            "Score: 0.31\n",
            "Document: company_info\n",
            "------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 72.06 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Question: Quels sont les principaux clients de l'entreprise ?\n",
            "Réponse: Cartier, Loewe, L'Oréal et Porsche\n",
            "Score: 0.42\n",
            "Document: services\n",
            "------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 71.44 Batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Question: Comment leur technologie améliore-t-elle la production ?\n",
            "Réponse: développement de concepts créatifs originaux\n",
            "Score: 0.19\n",
            "Document: services\n",
            "------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 72.41 Batches/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Question: Quels services proposent-ils ?\n",
            "Réponse: la création de workflows génératifs, la production de contenu itératif, \n",
            "        et le développement de concepts créatifs originaux\n",
            "Score: 0.51\n",
            "Document: services\n",
            "------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}