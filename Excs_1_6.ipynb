{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPjxVTQHpDQpIikdQ8AKHR6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ludoveltz/test_github_fev25/blob/main/Excs_1_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pymupdf\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "791ZSsNK5996",
        "outputId": "b298695f-1717-4011-972c-523b164cc4c7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymupdf\n",
            "  Downloading pymupdf-1.25.4-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading pymupdf-1.25.4-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymupdf\n",
            "Successfully installed pymupdf-1.25.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install requests PyPDF2 transformers torch\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "GZf1SrLM4fIV",
        "outputId": "491d5ba9-8020-405e-d5e1-d3e7d73c9d23"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.11/dist-packages (3.0.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.29.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m94.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸŒŸ Exercise 1: Cartographie de la Structure de l'Article\n",
        "\n",
        "## 1. Localisation des Sections\n",
        "\n",
        "### Introduction (Section 1)\n",
        "**RÃ©sumÃ©**: Cette section prÃ©sente le contexte des services d'IA gÃ©nÃ©rative basÃ©s sur les LLM dans un environnement d'entreprise. Elle Ã©tablit l'importance d'une architecture adaptÃ©e pour l'implÃ©mentation des LLM avec les donnÃ©es d'entreprise.\n",
        "\n",
        "### Related Work (Section 2)\n",
        "**RÃ©sumÃ©**: Examine les travaux antÃ©rieurs sur les architectures LLM et leur application dans les entreprises. Cette section analyse Ã©galement les diffÃ©rentes approches d'intÃ©gration des LLM avec les donnÃ©es d'entreprise existantes.\n",
        "\n",
        "### Methods (Section 3)\n",
        "**RÃ©sumÃ©**: DÃ©taille l'architecture proposÃ©e pour l'implÃ©mentation des services d'IA gÃ©nÃ©rative, incluant le traitement des donnÃ©es d'entreprise, les composants de sÃ©curitÃ©, et les mÃ©canismes d'intÃ©gration des LLM.\n",
        "\n",
        "### Experiment (Section 4)\n",
        "**RÃ©sumÃ©**: PrÃ©sente les rÃ©sultats de l'implÃ©mentation de l'architecture proposÃ©e, avec des mÃ©triques de performance, des cas d'utilisation concrets, et une Ã©valuation de l'efficacitÃ© du systÃ¨me.\n",
        "\n",
        "### Conclusion (Section 5)\n",
        "**RÃ©sumÃ©**: SynthÃ©tise les dÃ©couvertes principales et propose des recommandations pour l'implÃ©mentation future des services d'IA gÃ©nÃ©rative dans les entreprises.\n",
        "\n",
        "## 2. Format de l'Article\n",
        "\n",
        "L'article suit le format IMRaD (Introduction, Methods, Results, and Discussion) avec quelques adaptations :\n",
        "\n",
        "### Structure Standard IMRaD :\n",
        "- âœ… Introduction\n",
        "- âœ… MÃ©thodologie\n",
        "- âœ… RÃ©sultats\n",
        "- âœ… Discussion/Conclusion\n",
        "\n",
        "### Ã‰lÃ©ments SupplÃ©mentaires :\n",
        "- Section \"Related Work\" dÃ©taillÃ©e\n",
        "- Architecture proposÃ©e\n",
        "- Cas d'utilisation pratiques\n",
        "\n",
        "### Ã‰lÃ©ments Manquants ou Moins DÃ©veloppÃ©s :\n",
        "- Limitations dÃ©taillÃ©es\n",
        "- Perspectives futures approfondies\n",
        "- Discussion des implications Ã©thiques\n",
        "- Analyse comparative approfondie avec d'autres architectures\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9skk4kqa1jHM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸŒŸ Exercice 2 : Analyse Critique du Design ExpÃ©rimental\n",
        "\n",
        "## Analyse des Sections \"ExpÃ©rience\" et \"MÃ©thodes\"\n",
        "\n",
        "### 1. Question de Recherche\n",
        "\"Comment les dÃ©veloppeurs interagissent-ils avec les LLM dans leurs workflows de dÃ©veloppement et quels sont les dÃ©fis spÃ©cifiques qu'ils rencontrent lors de l'intÃ©gration et l'utilisation des LLM ?\"\n",
        "\n",
        "### 2. Type d'Ã‰tude\n",
        "- Ã‰tude empirique mixte (qualitative et quantitative)\n",
        "- Analyse systÃ©matique des pratiques de dÃ©veloppement\n",
        "- Collecte de donnÃ©es multi-sources incluant :\n",
        "  * EnquÃªtes dÃ©veloppeurs\n",
        "  * Analyse de code\n",
        "  * Documentation technique\n",
        "  * Issues GitHub\n",
        "\n",
        "### 3. Variables\n",
        "**Variables IndÃ©pendantes :**\n",
        "- ExpÃ©rience des dÃ©veloppeurs avec les LLM\n",
        "- Types d'applications dÃ©veloppÃ©es\n",
        "- Contextes d'utilisation des LLM\n",
        "- Frameworks et outils utilisÃ©s\n",
        "\n",
        "**Variables DÃ©pendantes :**\n",
        "- FrÃ©quence et types d'erreurs rencontrÃ©es\n",
        "- Temps de dÃ©veloppement\n",
        "- QualitÃ© du code produit\n",
        "- Satisfaction des dÃ©veloppeurs\n",
        "\n",
        "### 4. Datasets et Outils UtilisÃ©s\n",
        "**Datasets :**\n",
        "- Repositories GitHub publics\n",
        "- Forums de dÃ©veloppeurs\n",
        "- Documentation API\n",
        "- Logs d'erreurs\n",
        "- Retours d'expÃ©rience\n",
        "\n",
        "**Outils :**\n",
        "- Outils d'analyse de code\n",
        "- Frameworks LLM\n",
        "- Outils de tracking de bugs\n",
        "- SystÃ¨mes de versioning\n",
        "\n",
        "### 5. ContrÃ´les et Comparaisons\n",
        "- Comparaison avec mÃ©thodes de dÃ©veloppement traditionnelles\n",
        "- Benchmarking avec diffÃ©rents LLM\n",
        "- Analyse comparative des pratiques\n",
        "- Validation par experts du domaine\n",
        "\n",
        "### 6. ReproductibilitÃ© et Transparence\n",
        "**Forces :**\n",
        "- MÃ©thodologie clairement documentÃ©e\n",
        "- Code source disponible\n",
        "- DonnÃ©es d'analyse accessibles\n",
        "- CritÃ¨res d'Ã©valuation dÃ©finis\n",
        "\n",
        "**Limitations :**\n",
        "- Ã‰volution rapide des LLM\n",
        "- VariabilitÃ© des contextes d'utilisation\n",
        "- Biais potentiels dans la sÃ©lection des donnÃ©es\n",
        "- ComplexitÃ© des workflows de dÃ©veloppement\n"
      ],
      "metadata": {
        "id": "6t6o53fe2Ad2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸŒŸ Exercise 3: Ã‰valuation des MÃ©triques et Preuves\n",
        "\n",
        "## 1. Comparaisons de Performance\n",
        "- L'article prÃ©sente principalement des comparaisons entre diffÃ©rentes approches d'implÃ©mentation de services d'IA gÃ©nÃ©rative\n",
        "- Les comparaisons se concentrent sur l'architecture RAG (Retrieval-Augmented Generation) pour l'intÃ©gration des donnÃ©es d'entreprise\n",
        "- Il n'y a pas de comparaison directe et quantitative entre diffÃ©rents modÃ¨les LLM (comme GPT-3.5 vs GPT-4)\n",
        "\n",
        "## 2. MÃ©triques d'Ã‰valuation UtilisÃ©es\n",
        "L'article utilise principalement des mÃ©triques qualitatives :\n",
        "- FaisabilitÃ© de l'implÃ©mentation\n",
        "- CapacitÃ© d'intÃ©gration avec les systÃ¨mes existants\n",
        "- AdaptabilitÃ© aux diffÃ©rents cas d'usage\n",
        "- EfficacitÃ© de la rÃ©cupÃ©ration d'informations\n",
        "\n",
        "## 3. Pertinence des MÃ©triques\n",
        "Points Positifs :\n",
        "- Les mÃ©triques qualitatives sont appropriÃ©es pour une Ã©tude d'implÃ©mentation\n",
        "- L'accent mis sur l'intÃ©gration pratique correspond aux objectifs de l'Ã©tude\n",
        "\n",
        "Points Faibles :\n",
        "- Manque de mÃ©triques quantitatives\n",
        "- Absence de benchmarks standardisÃ©s\n",
        "- Pas d'Ã©valuation comparative systÃ©matique\n",
        "\n",
        "## 4. Suggestions d'AmÃ©lioration\n",
        "Pour renforcer la validitÃ© des rÃ©sultats, l'article pourrait inclure :\n",
        "\n",
        "MÃ©triques Quantitatives :\n",
        "- Temps de latence des requÃªtes\n",
        "- Taux de prÃ©cision des rÃ©ponses\n",
        "- Consommation de ressources\n",
        "- CoÃ»ts d'implÃ©mentation\n",
        "\n",
        "Ã‰valuations Qualitatives SupplÃ©mentaires :\n",
        "- Retours utilisateurs structurÃ©s\n",
        "- Ã‰valuation par des experts du domaine\n",
        "- Tests A/B comparatifs\n",
        "- Ã‰tudes de cas dÃ©taillÃ©es\n",
        "\n",
        "MÃ©triques Techniques :\n",
        "- Performances du systÃ¨me RAG\n",
        "- Vitesse de rÃ©cupÃ©ration des donnÃ©es\n",
        "- QualitÃ© de la gÃ©nÃ©ration\n",
        "- Taux d'erreur\n",
        "\n",
        "Validation Externe :\n",
        "- Comparaisons avec d'autres architectures\n",
        "- Benchmarks industriels\n",
        "- Ã‰valuation par des tiers\n",
        "- Ã‰tudes longitudinales\n"
      ],
      "metadata": {
        "id": "bWzumsyBdmuA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tabulate\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbOm8lMie_IT",
        "outputId": "7ae49feb-a1f4-466d-d0f6-b3201ced56a1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (0.9.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Importation des bibliothÃ¨ques\n",
        "from tabulate import tabulate\n",
        "from IPython.display import Markdown, display\n",
        "import pandas as pd\n",
        "\n",
        "# CrÃ©ation des notes Cornell\n",
        "def create_cornell_notes():\n",
        "    # CrÃ©ation du DataFrame pour la structure principale\n",
        "    cornell_data = {\n",
        "        'Questions/Termes ClÃ©s': [\n",
        "            'Qu\\'est-ce que le RAG ?',\n",
        "            'Comment fonctionne le processus de chunking ?',\n",
        "            'Quels sont les composants principaux ?',\n",
        "            'Comment s\\'effectue l\\'implÃ©mentation ?'\n",
        "        ],\n",
        "        'Notes': [\n",
        "            'â€¢ Retrieval Augmented Generation\\nâ€¢ MÃ©thode combinant LLM avec donnÃ©es externes\\nâ€¢ Permet d\\'amÃ©liorer prÃ©cision des rÃ©ponses',\n",
        "            'â€¢ DÃ©coupage documents en chunks\\nâ€¢ Conversion en embeddings vectoriels\\nâ€¢ Stockage dans base vectorielle',\n",
        "            'â€¢ Vector Store (ChromaDB)\\nâ€¢ Embedding Model\\nâ€¢ LLM pour gÃ©nÃ©ration',\n",
        "            '1. PrÃ©paration documents\\n2. CrÃ©ation embeddings\\n3. Stockage vectoriel\\n4. RequÃªte et rÃ©cupÃ©ration\\n5. GÃ©nÃ©ration rÃ©ponse'\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    # CrÃ©ation du DataFrame\n",
        "    df = pd.DataFrame(cornell_data)\n",
        "\n",
        "    # Affichage du titre\n",
        "    display(Markdown('# Notes Cornell - RAG Based Implementation Procedure'))\n",
        "\n",
        "    # Affichage de la structure principale\n",
        "    display(Markdown(tabulate(df, headers='keys', tablefmt='pipe', showindex=False)))\n",
        "\n",
        "    # Affichage du rÃ©sumÃ©\n",
        "    display(Markdown(\"\"\"\n",
        "## RÃ©sumÃ©\n",
        "\n",
        "La section 3.2.1 dÃ©taille l'implÃ©mentation d'un systÃ¨me RAG pour amÃ©liorer les rÃ©ponses des LLM avec des donnÃ©es d'entreprise.\n",
        "Le processus comprend le dÃ©coupage des documents, leur transformation en vecteurs, et leur stockage pour une rÃ©cupÃ©ration contextuelle.\n",
        "Cette approche permet d'obtenir des rÃ©ponses plus prÃ©cises et pertinentes en combinant la puissance des LLM avec des donnÃ©es spÃ©cifiques Ã  l'entreprise.\n",
        "\"\"\"))\n",
        "\n",
        "# ExÃ©cution de la fonction\n",
        "create_cornell_notes()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 671
        },
        "id": "HEEYbHlvfFSk",
        "outputId": "e362ce25-8e8e-4896-efe2-d0a61e83fe6f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (0.9.0)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Notes Cornell - RAG Based Implementation Procedure"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "| Questions/Termes ClÃ©s                         | Notes                                         |\n|:----------------------------------------------|:----------------------------------------------|\n| Qu'est-ce que le RAG ?                        | â€¢ Retrieval Augmented Generation              |\n|                                               | â€¢ MÃ©thode combinant LLM avec donnÃ©es externes |\n|                                               | â€¢ Permet d'amÃ©liorer prÃ©cision des rÃ©ponses   |\n| Comment fonctionne le processus de chunking ? | â€¢ DÃ©coupage documents en chunks               |\n|                                               | â€¢ Conversion en embeddings vectoriels         |\n|                                               | â€¢ Stockage dans base vectorielle              |\n| Quels sont les composants principaux ?        | â€¢ Vector Store (ChromaDB)                     |\n|                                               | â€¢ Embedding Model                             |\n|                                               | â€¢ LLM pour gÃ©nÃ©ration                         |\n| Comment s'effectue l'implÃ©mentation ?         | 1. PrÃ©paration documents                      |\n|                                               | 2. CrÃ©ation embeddings                        |\n|                                               | 3. Stockage vectoriel                         |\n|                                               | 4. RequÃªte et rÃ©cupÃ©ration                    |\n|                                               | 5. GÃ©nÃ©ration rÃ©ponse                         |"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n## RÃ©sumÃ©\n\nLa section 3.2.1 dÃ©taille l'implÃ©mentation d'un systÃ¨me RAG pour amÃ©liorer les rÃ©ponses des LLM avec des donnÃ©es d'entreprise. \nLe processus comprend le dÃ©coupage des documents, leur transformation en vecteurs, et leur stockage pour une rÃ©cupÃ©ration contextuelle. \nCette approche permet d'obtenir des rÃ©ponses plus prÃ©cises et pertinentes en combinant la puissance des LLM avec des donnÃ©es spÃ©cifiques Ã  l'entreprise.\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5W1H Analysis\n",
        "\n",
        "**Who (Qui) ?**\n",
        "Les auteurs de l'Ã©tude sont des chercheurs travaillant sur l'implÃ©mentation des services d'IA gÃ©nÃ©rative dans un contexte d'entreprise.\n",
        "\n",
        "**What (Quoi) ?**\n",
        "Une architecture d'application LLM basÃ©e sur les donnÃ©es d'entreprise pour l'implÃ©mentation de services d'IA gÃ©nÃ©rative, avec un focus particulier sur l'approche RAG (Retrieval-Augmented Generation).\n",
        "\n",
        "**When & Where (Quand & OÃ¹) ?**\n",
        "L'article a Ã©tÃ© publiÃ© sur arXiv en septembre 2023 (2309.01105).\n",
        "\n",
        "**Why (Pourquoi) ?**\n",
        "Le problÃ¨me est important car les entreprises ont besoin d'intÃ©grer efficacement les LLM avec leurs donnÃ©es propriÃ©taires tout en maintenant la sÃ©curitÃ© et la pertinence des rÃ©ponses gÃ©nÃ©rÃ©es.\n",
        "\n",
        "**How (Comment) ?**\n",
        "La solution a Ã©tÃ© implÃ©mentÃ©e via une architecture RAG qui combine :\n",
        "- PrÃ©paration et chunking des documents\n",
        "- CrÃ©ation d'embeddings vectoriels\n",
        "- Stockage dans une base de donnÃ©es vectorielle\n",
        "- SystÃ¨me de rÃ©cupÃ©ration contextuelle\n",
        "- GÃ©nÃ©ration de rÃ©ponses avec LLM\n",
        "\n",
        "### RÃ©sumÃ© en 4 phrases\n",
        "\n",
        "**Objectif :**\n",
        "L'Ã©tude visait Ã  dÃ©velopper une architecture pratique pour l'implÃ©mentation de services d'IA gÃ©nÃ©rative dans un contexte d'entreprise, en se concentrant sur l'intÃ©gration efficace des donnÃ©es propriÃ©taires avec les capacitÃ©s des LLM.\n",
        "\n",
        "**MÃ©thodologie :**\n",
        "Les chercheurs ont adoptÃ© une approche basÃ©e sur RAG, combinant des techniques de traitement de documents, d'indexation vectorielle et de gÃ©nÃ©ration de texte, tout en mettant l'accent sur la sÃ©curitÃ© et la pertinence des donnÃ©es.\n",
        "\n",
        "**DÃ©couvertes/Constructions :**\n",
        "Ils ont dÃ©veloppÃ© une architecture complÃ¨te qui permet aux entreprises d'implÃ©menter des services d'IA gÃ©nÃ©rative en utilisant leurs propres donnÃ©es, avec des mÃ©canismes de contrÃ´le et de rÃ©cupÃ©ration contextuelle.\n",
        "\n",
        "**Implications pratiques :**\n",
        "Cette architecture fournit un cadre concret pour les entreprises souhaitant dÃ©ployer des services d'IA gÃ©nÃ©rative, offrant un Ã©quilibre entre performance, sÃ©curitÃ© et pertinence des rÃ©ponses, tout en permettant une intÃ©gration harmonieuse avec les systÃ¨mes existants.\n"
      ],
      "metadata": {
        "id": "wX9goNnCe7eM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸŒŸ Exercise 6 : RÃ©flexion sur l'Architecture RAG + LLM\n",
        "\n",
        "### 1. Cas d'Utilisation\n",
        "**Assistant CrÃ©atif pour Marques de Luxe**\n",
        "Un systÃ¨me qui aide Ã  gÃ©nÃ©rer et valider des concepts crÃ©atifs en respectant l'ADN des marques de luxe.\n",
        "\n",
        "### 2. Pipeline RAG SimplifiÃ©\n",
        "\n",
        "**DonnÃ©es Ã  Collecter et Chunking :**\n",
        "- Archives des campagnes prÃ©cÃ©dentes\n",
        "- Guides de style des marques\n",
        "- Documentation technique des proportions historiques\n",
        "- SystÃ¨mes de tagging propriÃ©taires\n",
        "- Palettes de couleurs et signatures visuelles\n",
        "\n",
        "**Chunking Strategy :**\n",
        "- DÃ©coupage par Ã©lÃ©ments visuels cohÃ©rents\n",
        "- SÃ©paration des aspects techniques et crÃ©atifs\n",
        "- PrÃ©servation des associations couleur-concept\n",
        "- Maintien des proportions dans les chunks\n",
        "\n",
        "**Base de DonnÃ©es Vectorielle : Chroma DB**\n",
        "Raisons du choix :\n",
        "- Excellente gestion des embeddings multimodaux\n",
        "- IntÃ©gration facile avec les frameworks de ML\n",
        "- Performance optimale pour les requÃªtes visuelles\n",
        "- Support des mÃ©tadonnÃ©es riches\n",
        "\n",
        "**LLM Choisi : GPT-4 avec Fine-tuning**\n",
        "Justification :\n",
        "- CapacitÃ©s multimodales avancÃ©es\n",
        "- ComprÃ©hension sophistiquÃ©e du contexte\n",
        "- PossibilitÃ© de fine-tuning sur donnÃ©es luxe\n",
        "- Support des prompts complexes\n",
        "\n",
        "**Gestion des Hallucinations :**\n",
        "- SystÃ¨me de validation par rapport aux guides de style\n",
        "- VÃ©rification des proportions historiques\n",
        "- ContrÃ´le de cohÃ©rence avec l'ADN de marque\n",
        "- Feedback loop avec experts crÃ©atifs\n",
        "\n",
        "### 3. DÃ©fis AnticipÃ©s\n",
        "\n",
        "**DÃ©fis Techniques :**\n",
        "- IntÃ©gration complexe des donnÃ©es visuelles et textuelles\n",
        "- Maintien de la cohÃ©rence dans les gÃ©nÃ©rations\n",
        "- Performance du systÃ¨me en temps rÃ©el\n",
        "- Gestion des versions des assets\n",
        "\n",
        "**DÃ©fis CrÃ©atifs :**\n",
        "- PrÃ©servation de l'unicitÃ© de chaque marque\n",
        "- Balance entre innovation et tradition\n",
        "- Validation des propositions crÃ©atives\n",
        "- Maintien de l'excellence artisanale\n",
        "\n",
        "**DÃ©fis d'ImplÃ©mentation :**\n",
        "- Formation des Ã©quipes crÃ©atives\n",
        "- IntÃ©gration aux workflows existants\n",
        "- SÃ©curitÃ© des donnÃ©es sensibles\n",
        "- Ã‰volutivitÃ© du systÃ¨me\n",
        "\n",
        "**DÃ©fis SpÃ©cifiques au Luxe :**\n",
        "- Respect des standards haute couture\n",
        "- Maintien de l'exclusivitÃ©\n",
        "- Protection de la propriÃ©tÃ© intellectuelle\n",
        "- Adaptation aux tendances tout en prÃ©servant l'hÃ©ritage\n"
      ],
      "metadata": {
        "id": "zgUlxxfTga_F"
      }
    }
  ]
}