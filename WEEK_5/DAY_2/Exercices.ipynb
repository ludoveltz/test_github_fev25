{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/ludovicveltz/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ludovicveltz/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Importation des bibliothèques nécessaires\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Téléchargement des ressources NLTK nécessaires\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# 1. Chargement des données\n",
    "df_imdb = pd.read_csv('/Users/ludovicveltz/Documents/Bootcamp_GENAI_2025/Crashcourse/WEEK_5/DAY_2/DATASET/IMDB_Dataset.csv')\n",
    "df = df_imdb.iloc[:len(df_imdb) // 5]  # Utiliser 20% des données\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Premières lignes :\n",
      "                                              review sentiment\n",
      "0  One of the other reviewers has mentioned that ...  positive\n",
      "1  A wonderful little production. <br /><br />The...  positive\n",
      "2  I thought this was a wonderful way to spend ti...  positive\n",
      "3  Basically there's a family where a little boy ...  negative\n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
      "\n",
      "Dimensions : (10000, 2)\n",
      "\n",
      "Types des colonnes :\n",
      "review       object\n",
      "sentiment    object\n",
      "dtype: object\n",
      "\n",
      "Valeurs manquantes :\n",
      "review       0\n",
      "sentiment    0\n",
      "dtype: int64\n",
      "\n",
      "Premières reviews :\n",
      "                                              review sentiment\n",
      "0  One of the other reviewers has mentioned that ...  positive\n",
      "1  A wonderful little production. <br /><br />The...  positive\n",
      "2  I thought this was a wonderful way to spend ti...  positive\n",
      "3  Basically there's a family where a little boy ...  negative\n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n"
     ]
    }
   ],
   "source": [
    "# 2. & 3. Exploration initiale\n",
    "print(\"Premières lignes :\")\n",
    "print(df.head())\n",
    "print(\"\\nDimensions :\", df.shape)\n",
    "print(\"\\nTypes des colonnes :\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# 4. Vérification des valeurs manquantes\n",
    "print(\"\\nValeurs manquantes :\")\n",
    "print(df.isnull().sum())\n",
    "df = df.dropna()\n",
    "\n",
    "# 5. Affichage des 5 premières reviews\n",
    "print(\"\\nPremières reviews :\")\n",
    "print(df[['review', 'sentiment']].head())\n",
    "\n",
    "# 6. Fonction de comptage des mots\n",
    "def count_words(text):\n",
    "    return len(text.split())\n",
    "\n",
    "df['words_count'] = df['review'].apply(count_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nombre de doublons : 17\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing\n",
    "def simple_preprocessing(text):\n",
    "    # Conversion en minuscules\n",
    "    text = text.lower()\n",
    "    # Suppression des balises HTML\n",
    "    text = re.sub(r'<br\\s*/>', ' ', text)\n",
    "    # Suppression des URLs\n",
    "    text = re.sub(r'http\\S+|www.\\S+', '', text)\n",
    "    # Suppression des hashtags et @\n",
    "    text = re.sub(r'[@#]\\w+', '', text)\n",
    "    # Suppression de la ponctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Tokenization et suppression des stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Application du preprocessing\n",
    "df['processed_review'] = df['review'].apply(simple_preprocessing)\n",
    "\n",
    "# Vérification des doublons\n",
    "print(\"\\nNombre de doublons :\", df.duplicated().sum())\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Stemming\n",
    "def stemming(text):\n",
    "    ps = PorterStemmer()\n",
    "    tokens = text.split()\n",
    "    stemmed = [ps.stem(word) for word in tokens]\n",
    "    return ' '.join(stemmed)\n",
    "\n",
    "df['stemmed_review'] = df['processed_review'].apply(stemming)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Formes des données :\n",
      "X_train shape: (6988, 49871)\n",
      "X_test shape: (2995, 49871)\n",
      "y_train shape: (6988,)\n",
      "y_test shape: (2995,)\n"
     ]
    }
   ],
   "source": [
    "# Préparation des données\n",
    "# Binarisation des sentiments\n",
    "df['sentiment_binary'] = (df['sentiment'] == 'positive').astype(int)\n",
    "\n",
    "# Vectorisation TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df['stemmed_review'])\n",
    "y = df['sentiment_binary']\n",
    "\n",
    "# Split des données\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"\\nFormes des données :\")\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Précision du modèle : 0.8761268781302171\n",
      "\n",
      "Matrice de confusion :\n",
      "[[1269  219]\n",
      " [ 152 1355]]\n",
      "\n",
      "Rapport de classification :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.85      0.87      1488\n",
      "           1       0.86      0.90      0.88      1507\n",
      "\n",
      "    accuracy                           0.88      2995\n",
      "   macro avg       0.88      0.88      0.88      2995\n",
      "weighted avg       0.88      0.88      0.88      2995\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Modèle de régression logistique\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Évaluation\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"\\nPrécision du modèle :\", accuracy)\n",
    "\n",
    "print(\"\\nMatrice de confusion :\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nRapport de classification :\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prédictions :\n",
      "Review: I loved this movie!\n",
      "Sentiment prédit: positive\n",
      "\n",
      "Review: This movie was a bad comedy movie!\n",
      "Sentiment prédit: negative\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test de prédictions\n",
    "def predict_sentiment(text):\n",
    "    # Prétraitement\n",
    "    processed = simple_preprocessing(text)\n",
    "    stemmed = stemming(processed)\n",
    "    # Vectorisation\n",
    "    vectorized = vectorizer.transform([stemmed])\n",
    "    # Prédiction\n",
    "    prediction = model.predict(vectorized)\n",
    "    return \"positive\" if prediction[0] == 1 else \"negative\"\n",
    "\n",
    "# Test des phrases\n",
    "test_reviews = [\n",
    "    \"I loved this movie!\",\n",
    "    \"This movie was a bad comedy movie!\"\n",
    "]\n",
    "\n",
    "print(\"\\nPrédictions :\")\n",
    "for review in test_reviews:\n",
    "    sentiment = predict_sentiment(review)\n",
    "    print(f\"Review: {review}\")\n",
    "    print(f\"Sentiment prédit: {sentiment}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision du modèle amélioré : 0.8874791318864774\n",
      "\n",
      "Prédictions avec le modèle amélioré :\n",
      "\n",
      "Critique : This movie was absolutely brilliant, the acting was superb and the story kept me engaged throughout the entire film. 9/10\n",
      "Sentiment prédit : positive\n",
      "\n",
      "Critique : Despite good intentions, the movie falls flat with poor acting and a confusing plot. The special effects couldn't save it. 3/10\n",
      "Sentiment prédit : negative\n",
      "\n",
      "Critique : A decent film but nothing spectacular. The performances were okay but the story was predictable. 6/10\n",
      "Sentiment prédit : negative\n",
      "\n",
      "Critique : One of the worst movies I've ever seen. Complete waste of time and money. The plot made no sense.\n",
      "Sentiment prédit : negative\n",
      "\n",
      "Critique : While not perfect, the film manages to deliver solid entertainment with strong performances and beautiful cinematography.\n",
      "Sentiment prédit : positive\n"
     ]
    }
   ],
   "source": [
    "# BONUS : \n",
    "def enhanced_preprocessing(text):\n",
    "    # Gestion spécifique des expressions courantes dans les critiques de films\n",
    "    text = text.lower()\n",
    "    # Remplacer les contractions courantes\n",
    "    text = re.sub(r\"won't\", \"will not\", text)\n",
    "    text = re.sub(r\"can't\", \"cannot\", text)\n",
    "    text = re.sub(r\"n't\", \" not\", text)\n",
    "    # Gestion des expressions spécifiques aux films\n",
    "    text = re.sub(r\"(\\d+)/10\", \"rating\", text)  # Remplacer les notes /10\n",
    "    text = re.sub(r\"oscar[s]?\", \"award\", text)  # Standardiser les références aux oscars\n",
    "    # Nettoyage standard\n",
    "    text = re.sub(r'<br\\s*/>', ' ', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Tokenization et stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    # Garder certains mots importants pour les critiques\n",
    "    important_words = {'not', 'no', 'but', 'very', 'good', 'bad'}\n",
    "    stop_words = stop_words - important_words\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# 2. Modifier la fonction improve_imdb_model pour utiliser la fonction externe\n",
    "def improve_imdb_model():\n",
    "    vectorizer_improved = TfidfVectorizer(\n",
    "        preprocessor=enhanced_preprocessing,\n",
    "        ngram_range=(1, 3),     \n",
    "        max_features=15000,     \n",
    "        min_df=3,              \n",
    "        max_df=0.95           \n",
    "    )\n",
    "\n",
    "    # Préparation des données\n",
    "    X_improved = vectorizer_improved.fit_transform(df['review'])\n",
    "    \n",
    "    # Split avec stratification\n",
    "    X_train_imp, X_test_imp, y_train_imp, y_test_imp = train_test_split(\n",
    "        X_improved, \n",
    "        df['sentiment_binary'],\n",
    "        test_size=0.3,\n",
    "        random_state=42,\n",
    "        stratify=df['sentiment_binary']\n",
    "    )\n",
    "\n",
    "    # Modèle amélioré\n",
    "    model_improved = LogisticRegression(\n",
    "        C=1.0,\n",
    "        class_weight='balanced',\n",
    "        max_iter=200,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Entraînement\n",
    "    model_improved.fit(X_train_imp, y_train_imp)\n",
    "    \n",
    "    # Évaluation\n",
    "    y_pred_imp = model_improved.predict(X_test_imp)\n",
    "    accuracy_imp = accuracy_score(y_test_imp, y_pred_imp)\n",
    "    \n",
    "    return vectorizer_improved, model_improved, accuracy_imp\n",
    "\n",
    "# 3. Test avec les mêmes critiques\n",
    "test_reviews_imdb = [\n",
    "    \"This movie was absolutely brilliant, the acting was superb and the story kept me engaged throughout the entire film. 9/10\",\n",
    "    \"Despite good intentions, the movie falls flat with poor acting and a confusing plot. The special effects couldn't save it. 3/10\",\n",
    "    \"A decent film but nothing spectacular. The performances were okay but the story was predictable. 6/10\",\n",
    "    \"One of the worst movies I've ever seen. Complete waste of time and money. The plot made no sense.\",\n",
    "    \"While not perfect, the film manages to deliver solid entertainment with strong performances and beautiful cinematography.\"\n",
    "]\n",
    "\n",
    "# 4. Exécution et test\n",
    "vectorizer_improved, model_improved, accuracy_improved = improve_imdb_model()\n",
    "\n",
    "print(f\"Précision du modèle amélioré : {accuracy_improved}\")\n",
    "\n",
    "print(\"\\nPrédictions avec le modèle amélioré :\")\n",
    "for review in test_reviews_imdb:\n",
    "    processed = enhanced_preprocessing(review)\n",
    "    vectorized = vectorizer_improved.transform([processed])\n",
    "    prediction = model_improved.predict(vectorized)\n",
    "    sentiment = \"positive\" if prediction[0] == 1 else \"negative\"\n",
    "    \n",
    "    print(f\"\\nCritique : {review}\")\n",
    "    print(f\"Sentiment prédit : {sentiment}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_m1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
